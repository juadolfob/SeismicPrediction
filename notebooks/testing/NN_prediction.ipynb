{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from IPython import get_ipython\n",
    "from matplotlib import cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.manifold import Isomap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "\n",
    "pdf = pd.DataFrame\n",
    "\n",
    "%matplotlib qt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Local library import\n",
    "We import all the required local libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import model\n",
    "from model import CalculateFeatures, SelectFeatures, REGION"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameter definition\n",
    "We set all relevant parameters for our notebook. By convention, parameters are uppercase, while all the other variables follow Python's guidelines."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "USE_CACHED_FEATURES = True\n",
    "MAGNITUDE_THRESHOLD = 5.5\n",
    "WINDOW_SIZE = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data import\n",
    "We retrieve all the required data for the analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating new features...\n"
     ]
    }
   ],
   "source": [
    "# delete cached features to generate new features\n",
    "if model.features_in_cache() and USE_CACHED_FEATURES:\n",
    "    print(\"loading cached features...\")\n",
    "    features = model.load_features_from_cache()\n",
    "    print(\"done.\")\n",
    "else:\n",
    "    print(\"Calculating new features...\")\n",
    "    df = model.load_data('../../data/DATA_2.csv')\n",
    "    df = df[(df.Longitude > REGION.SOUTH.x1) & (df.Latitude < REGION.SOUTH.y1) &\n",
    "            (df.Longitude < REGION.SOUTH.x2) & (df.Latitude > REGION.SOUTH.y2)]\n",
    "    df = df[(df.Datetime.dt.year >= 2017) & (df.Magnitude >= 3.8)]\n",
    "    df_model = CalculateFeatures(df, WINDOW_SIZE, trim_features=True, mag_threshold=MAGNITUDE_THRESHOLD)\n",
    "    print(\"New features generated.\")\n",
    "    features = df_model.features\n",
    "    features.to_csv(\"../../model/features_cache/features.csv\", index=False)\n",
    "    print(\"New features saved.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Feature selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.FEATURES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "X = features[model.FEATURES]\n",
    "Y_CONTINUOUS = features[model.TARGETS.CONTINUOUS]\n",
    "Y_CATEGORICAL = features[model.TARGETS.CATEGORICAL]\n",
    "selected_features = SelectFeatures(features=X, targets=Y_CONTINUOUS, corr_threshold=.99)\n",
    "X = X.to_numpy()\n",
    "Y_CONTINUOUS = Y_CONTINUOUS.to_numpy()\n",
    "Y_CATEGORICAL = Y_CATEGORICAL.to_numpy()\n",
    "corrMatrix = features[model.ALL_FEATURES].corr()\n",
    "sns.heatmap(corrMatrix, yticklabels=corrMatrix.columns, xticklabels=corrMatrix.columns, cmap=\"bwr\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_features[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(Y_CATEGORICAL.T[0])\n",
    "neg, pos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Normalize and shorten data\n",
    "(self.window_size * (T[1] - T[0])) / math.sqrt(self.window_size * T[0] + T[1])<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_CONTINUOUS_Scaler = MinMaxScaler()\n",
    "X_Scaler = MinMaxScaler()\n",
    "X_norm64 = X_Scaler.fit_transform(X)\n",
    "Y_CONTINUOUS_norm64 = Y_CONTINUOUS_Scaler.fit_transform(Y_CONTINUOUS)\n",
    "X_norm32 = X_norm64.astype(np.float32)\n",
    "Y_CONTINUOUS_norm32 = Y_CONTINUOUS.astype(np.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap(\"viridis\")\n",
    "colors_continuous = list(map(cmap, Y_CONTINUOUS_norm64.T[0]))\n",
    "color_categorical = list(map(cmap, Y_CATEGORICAL.T[0] * .90))\n",
    "sizes = np.power(10, Y_CONTINUOUS_norm64.T[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "X_norm_32_train, X_norm_32_test, Y_CONTINUOUS_norm32_train, Y_CONTINUOUS_norm32_test, Y_CATEGORICAL_train, Y_CATEGORICAL_test = train_test_split(\n",
    "    X_norm32, Y_CONTINUOUS_norm32, Y_CATEGORICAL, test_size=0.33, random_state=RANDOM_STATE)\n",
    "X_norm_32_train, X_norm_32_val, Y_CONTINUOUS_norm32_train, Y_CONTINUOUS_norm32_val, Y_CATEGORICAL_train, Y_CATEGORICAL_val = train_test_split(\n",
    "    X_norm_32_train, Y_CONTINUOUS_norm32_train, Y_CATEGORICAL_train, test_size=0.33, random_state=RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def make_NN_model(metrics=model.METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    NN_model = keras.Sequential([\n",
    "        keras.layers.Dense(X_norm_32_train.shape[-1], activation='relu', input_shape=(X_norm_32_train.shape[-1],)),\n",
    "        # minimize\n",
    "        # keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(X_norm_32_train.shape[-1], activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias),\n",
    "    ])\n",
    "\n",
    "    NN_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics)\n",
    "\n",
    "    return NN_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NN_model = make_NN_model()\n",
    "NN_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NN_model.predict(X_norm_32_train[:10])\n",
    "\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "NN_model.save_weights(initial_weights)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "\n",
    "def plot_metrics(history):\n",
    "    metrics = ['loss', 'prc', 'Precision', 'Recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\", \" \").capitalize()\n",
    "        plt.subplot(2, 2, n + 1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_' + metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        if metric == 'loss':\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == 'auc':\n",
    "            plt.ylim([0.8, 1])\n",
    "        else:\n",
    "            plt.ylim([0, 1])\n",
    "\n",
    "        plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NN_model = make_NN_model()\n",
    "NN_model.load_weights(initial_weights)\n",
    "baseline_history = NN_model.fit(\n",
    "    X_norm_32_train,\n",
    "    Y_CATEGORICAL_train,\n",
    "    batch_size=model.BATCH_SIZE,\n",
    "    epochs=model.EPOCHS,\n",
    "    validation_data=(X_norm_32_val, Y_CATEGORICAL_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_metrics(baseline_history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_predictions_baseline = NN_model.predict(X_norm_32_train, batch_size=model.BATCH_SIZE)\n",
    "test_predictions_baseline = NN_model.predict(X_norm_32_test, batch_size=model.BATCH_SIZE)\n",
    "\n",
    "baseline_results = NN_model.evaluate(X_norm_32_test, Y_CATEGORICAL_test,\n",
    "                                     batch_size=model.BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(NN_model.metrics_names, baseline_results):\n",
    "    print(name, ': ', value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cm(Y_CATEGORICAL_test, test_predictions_baseline)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#    WEIGHTED"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight_for_0 = (1 / (features.shape[0] - Y_CATEGORICAL.sum())) * (features.shape[0] / 2.0)\n",
    "weight_for_1 = (1 / Y_CATEGORICAL.sum()) * (features.shape[0] / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weighted_model = make_NN_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    X_norm_32_train,\n",
    "    Y_CATEGORICAL_train,\n",
    "    batch_size=model.BATCH_SIZE,\n",
    "    epochs=model.EPOCHS,\n",
    "    validation_data=(X_norm_32_val, Y_CATEGORICAL_val),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_metrics(weighted_history)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_predictions_weighted = weighted_model.predict(X_norm_32_train, batch_size=model.BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(X_norm_32_test, batch_size=model.BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weighted_results = weighted_model.evaluate(X_norm_32_test, Y_CATEGORICAL_test,\n",
    "                                           batch_size=model.BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "    print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(Y_CATEGORICAL_test, test_predictions_weighted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pos_features = X_norm_32_train[Y_CATEGORICAL_train.T[0]]\n",
    "neg_features = X_norm_32_train[~Y_CATEGORICAL_train.T[0]]\n",
    "\n",
    "pos_labels = Y_CATEGORICAL_train[Y_CATEGORICAL_train.T[0]]\n",
    "neg_labels = Y_CATEGORICAL_train[~Y_CATEGORICAL_train.T[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ids = np.arange(len(pos_features))\n",
    "choices = np.random.choice(ids, len(neg_features))\n",
    "\n",
    "res_pos_features = pos_features[choices]\n",
    "res_pos_labels = pos_labels[choices]\n",
    "\n",
    "res_pos_features.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n",
    "resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
    "\n",
    "order = np.arange(len(resampled_labels))\n",
    "np.random.shuffle(order)\n",
    "resampled_features = resampled_features[order]\n",
    "resampled_labels = resampled_labels[order]\n",
    "\n",
    "resampled_features.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100000\n",
    "\n",
    "\n",
    "def make_ds(features, labels):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((features, labels))  #.cache()\n",
    "    ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
    "    return ds\n",
    "\n",
    "\n",
    "pos_ds = make_ds(pos_features, pos_labels)\n",
    "neg_ds = make_ds(neg_features, neg_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for features, label in pos_ds.take(1):\n",
    "    print(\"Features:\\n\", features.numpy())\n",
    "    print()\n",
    "    print(\"Label: \", label.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
    "resampled_ds = resampled_ds.batch(model.BATCH_SIZE).prefetch(2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for features, label in resampled_ds.take(1):\n",
    "    print(label.numpy().mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resampled_steps_per_epoch = np.ceil(2.0 * neg / model.BATCH_SIZE)\n",
    "resampled_steps_per_epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resampled_model = make_NN_model()\n",
    "resampled_model.load_weights(initial_weights)\n",
    "\n",
    "# Reset the bias to zero, since this dataset is balanced.\n",
    "output_layer = resampled_model.layers[-1]\n",
    "output_layer.bias.assign([0])\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_norm_32_val, Y_CATEGORICAL_val)).cache()\n",
    "val_ds = val_ds.batch(model.BATCH_SIZE).prefetch(2)\n",
    "\n",
    "resampled_history = resampled_model.fit(\n",
    "    resampled_ds,\n",
    "    epochs=model.EPOCHS,\n",
    "    steps_per_epoch=resampled_steps_per_epoch,\n",
    "    validation_data=val_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_metrics(resampled_history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_predictions_resampled = resampled_model.predict(X_norm_32_train, batch_size=model.BATCH_SIZE)\n",
    "test_predictions_resampled = resampled_model.predict(X_norm_32_test, batch_size=model.BATCH_SIZE)\n",
    "\n",
    "resampled_results = resampled_model.evaluate(X_norm_32_test, Y_CATEGORICAL_test,\n",
    "                                             batch_size=model.BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(resampled_model.metrics_names, resampled_results):\n",
    "    print(name, ': ', '%.6g' % value)\n",
    "print()\n",
    "\n",
    "plot_cm(Y_CATEGORICAL_test, test_predictions_resampled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.9\n",
    "loss :  0.198021\n",
    "tp :  867\n",
    "fp :  436\n",
    "tn :  6770\n",
    "fn :  118\n",
    "Accuracy :  0.932365\n",
    "Precision :  0.665388\n",
    "Recall :  0.880203\n",
    "NPV :  0.982869\n",
    "R score :  0.819698\n",
    "MCC :  0.728954\n",
    "FPR :  0.939495\n",
    "auc :  0.970255\n",
    "prc :  0.871329"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3.8\n",
    "loss :  0.180167\n",
    "tp :  898\n",
    "fp :  528\n",
    "tn :  6678\n",
    "fn :  87h\n",
    "Accuracy :  0.924918\n",
    "Precision :  0.629734\n",
    "Recall :  0.911675\n",
    "NPV :  0.98714\n",
    "R score :  0.838403\n",
    "MCC :  0.719158\n",
    "FPR :  0.926728\n",
    "auc :  0.976313\n",
    "prc :  0.907027\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "seismicprediction",
   "language": "python",
   "display_name": "SeismicPrediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "### Library import\n",
     "We import all the required Python libraries\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}